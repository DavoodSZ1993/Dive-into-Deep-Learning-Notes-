{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLuerYnqhxEUHWAuIGGt6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive-into-Deep-Learning-Notes-/blob/main/07_CNN_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Notes"
      ],
      "metadata": {
        "id": "pNZpIcA7ejHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch.t(input)`: Expects input to be <= 2D tensor and transposes dimensions 0, 1."
      ],
      "metadata": {
        "id": "U63BU_RIfR5f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLjzV0bPedE0",
        "outputId": "7de3842f-e755-4661-9af3-eaa6e6428312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2.],\n",
              "         [3., 4.]]), tensor([[1., 3.],\n",
              "         [2., 4.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "A = torch.tensor([[1.0, 2.0],\n",
        "                  [3.0, 4.0]])\n",
        "\n",
        "A, A.t()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution Layers "
      ],
      "metadata": {
        "id": "sl1h2rpjgJ5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `nn.Conv2d(in_channels, out_channels, kernel_size, bias=True)`: Applies a 2D convolution over an input signal composed of several input planes.\n",
        "* `in_channels`: Number of channels in the input image\n",
        "* `out_channels`: Number pf channels produced by the convolution operator.\n",
        "* `kernel_size`: Size of the convolution kernel.\n",
        "* `bias=True`: Ig `True`, adds a learnable bias to the output."
      ],
      "metadata": {
        "id": "jTxIapeTgfxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When isntantiate from the `nn.Conv2d()` class, the images applied to this kind of layer should have the format $(N, C_{in}, H, W)$ where:\n",
        "\n",
        "* $N$ is batch size.\n",
        "* $C_{in}$ denotes number of channels."
      ],
      "metadata": {
        "id": "KDgbKQTClK5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "\n",
        "Y = torch.zeros((6, 7))\n",
        "Y[:, 1] = 1\n",
        "Y[:, 5] = -1\n",
        "\n",
        "X, Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKjPtCxoiLon",
        "outputId": "48156d2d-7709-4ad4-907b-6cffeec1a44d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [1., 1., 0., 0., 0., 0., 1., 1.]]),\n",
              " tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "conv2d.weight.data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94YHGbSfi-EH",
        "outputId": "170ed48a-e2d3-4aa2-b06b-fb87a468f1bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0020, 0.5905]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Notes"
      ],
      "metadata": {
        "id": "lYwdizpaem8o"
      }
    }
  ]
}