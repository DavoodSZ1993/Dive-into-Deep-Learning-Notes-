{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP08OJQjJmpYkJd0MFzF/QM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive-into-Deep-Learning-Notes-/blob/main/08_modern_CNNs_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks\n",
        "\n",
        "* **Convolution** (`nn.Conv2d()` & `nn.LazyConv2d()`): Given the input size ($n_h\\times n_w$), and the kernel size ($k_h \\times k_w$), the output size is as follows:\n",
        "$$\n",
        "(n_h - k_h + 1) \\times (n_w - k_w + 1)\n",
        "$$\n",
        "\n",
        "* **Padding**: Given the input size ($n_h \\times n_w$), the kernel size ($k_h \\times k_w$), when adding a total of $p_h$ rows of padding and a total of $p_w$ columns of padding, the output size will be as follows:\n",
        "$$\n",
        "(n_h - k_h + p_h + 1) \\times (n_w - k_w + p_w + 1)\n",
        "$$\n",
        "\n",
        "The `padding=1` argument in `nn.Conv2d()` will add one row at top, and one row at bottom ($p_h=2$), and one column at left and one column at right ($p_w=2$)\n",
        "\n",
        "* **Stride**: Given the input size ($n_h \\times n_w$), the kernel size ($k_h \\times k_w$), padding size ($p_h \\times p_w$), when the stride for hight is $s_h$ and th stride for the width is $s_w$, the output shape will be as follows:\n",
        "$$\n",
        "[{n_h - k_h + p_h + s_h \\over s_h}] \\times [{n_w - k_w + p_w + s_w \\over s_w}] \n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "ODsC39LJumFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class `nn.AdaptiveAvgPool2d(output_size)`: \n",
        "Applies a 2D adaptive average pooling over an input signal composed of several input planes. \n",
        "\n",
        "* input: ($N, C, H_{in}, W_{in}$) or ($C, H_{in}, W_{in}$)\n",
        "output: ($N, C, S_0, S_1$) or ($C, S_0, S_1$) where $S$=`output_size`."
      ],
      "metadata": {
        "id": "AfBEWfbY5xy0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GBp4fYgQuUgj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 2],\n",
        "                  [3, 4]], dtype=torch.float32)  # 1 x 1 2 x 2\n",
        "\n",
        "net = nn.AdaptiveAvgPool2d((1))   # 1 x 1 x 1 x 1\n",
        "\n",
        "net(X), X.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1MiJTUV7iwX",
        "outputId": "667ee445-e586-48e4-f16d-5a62084cff69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2.5000]]), tensor(2.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization\n",
        "\n",
        "$$\n",
        "BN(ùê±) = ùõÑ ‚äó {ùê± - ùùªÃÇ_{ùñÅ} \\over ùõîÃÇ_{ùñÅ}} + ùõÉ\n",
        "$$\n",
        "where ùñÅ is minibatch and $ùô≠ ‚àà ùñÅ$. $ùì§ÃÇ$ is the sample mean and $ùõîÃÇ_{ùñÅ}$ is the sample standard deviation. ùõÑ and ùõÉ are scale parameter and shift parameter respectively. \n"
      ],
      "metadata": {
        "id": "Q1acNSfxAsGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully Connected Layers\n",
        "\n",
        "When using a fully connected layer, calculate the mean and variance on the feature dimension.\n",
        "$$\n",
        "ùê° = Œ¶(BN(ùëæùê± + ùêõ))\n",
        "$$\n"
      ],
      "metadata": {
        "id": "AzHF70uBAvKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 2],\n",
        "                  [3, 4]], dtype=torch.float32)\n",
        "\n",
        "X.mean(dim=0, keepdim=True), X.mean(dim=1), X.mean(dim=0, keepdim=True).shape, X.mean(dim=1).shape   # mean along rows, mean along columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wLePTPbPy5i",
        "outputId": "40b2345c-2647-4d55-a5a2-16198a67d7a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2., 3.]]),\n",
              " tensor([1.5000, 3.5000]),\n",
              " torch.Size([1, 2]),\n",
              " torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `torch.nn.BatchNorm1d(num_features)`: Applies Batch Normalization over a 2D or 3D input.\n",
        "* Input: ($N, C$) or ($N, C, L$) where $N$ is the batch size, $C$ is the number of features or channels, and $L$ is the length of sequence.\n",
        "* Output: ($N, C$) or ($N, C, L$) (same shape as input)."
      ],
      "metadata": {
        "id": "PGh63bOmcSAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(50, 200)\n",
        "\n",
        "net = nn.BatchNorm1d(num_features=200)\n",
        "\n",
        "net(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnWk2eqJeNjv",
        "outputId": "6aae55ac-27cd-407f-81a4-185c760e2659"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `torch.nn.LazyBatchNorm1d()`: A `torch.nn.BatchNorm1d` module with lazy initialization of the `num_feature` argument."
      ],
      "metadata": {
        "id": "Ejrn5hmPfGdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(50, 200)\n",
        "\n",
        "net = nn.LazyBatchNorm1d() # num_features is inferred from the input.\n",
        "\n",
        "net(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBNmbFn1fY1D",
        "outputId": "67e01c95-dc71-47cb-e4b1-08f582aa7b73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layers\n",
        "\n",
        "When using a two-dimensional convolution layer, calculate the mean and variance on the channel dimension (dim=1).\n",
        "\n",
        "* Assume that each minibatches contain $m$ examples and that for each channel, the output of the convolution has height $p$ and width $q$. For convolutional layers, we carry out each batch normalization over $m.p.q$ elements per output channels simultaneously."
      ],
      "metadata": {
        "id": "xHLpmJEbAzwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((10, 10, 20, 20), dtype=torch.float32)\n",
        "\n",
        "mean = X.mean(dim=(0, 2, 3), keepdim=True)  # Averaging over channels\n",
        "mean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Rg7Asogddr",
        "outputId": "54705d8c-dbe2-412c-f174-64697c6ad64a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `torch.nn.BatchNorm2d(num_features)`: Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension.)\n",
        "* Input: ($N, C, W, H$).\n",
        "* Output: ($N, C, W, H$) same shape as input."
      ],
      "metadata": {
        "id": "TIv5DgnMhKek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((10, 10, 20, 20), dtype=torch.float32)\n",
        "\n",
        "net = nn.BatchNorm2d(10)\n",
        "net(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlAGJqIHh00s",
        "outputId": "2ae7828b-9359-4ca0-c99e-3516ae8992b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `nn.torch.LazyBatchNorm2d()`: A `torch.nn.BatchNorm2d` module with lazy initialization of the `num_features` argument."
      ],
      "metadata": {
        "id": "VRfKHsfVicHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((10, 10, 20, 20), dtype=torch.float32)\n",
        "\n",
        "net = nn.LazyBatchNorm2d()  # Infer number of features from the input!\n",
        "net(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zFPGJQPisBr",
        "outputId": "fdbf9b95-9143-45c3-ea10-02c952018d9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization\n",
        "\n",
        "Batch normalization over a batch with size of 1."
      ],
      "metadata": {
        "id": "JmLMmUBsA43b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Notes"
      ],
      "metadata": {
        "id": "c_N3og0-kIQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `add_module(name. module)` of `nn.Module` class: Adds a child module to the current module. The module can be accessed as an attribute using the given name.\n",
        "\n",
        "The following networks are the same."
      ],
      "metadata": {
        "id": "xUmr7dq8k4iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.LazyLinear(10), nn.ReLU(),\n",
        "        nn.LazyLinear(1))\n",
        "    \n",
        "class Net1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.add_module(name='linear1', module=nn.LazyLinear(10))\n",
        "    self.add_module(name='relu1', module=nn.ReLU())\n",
        "    self.add_module(name='linear2', module=nn.LazyLinear(1))"
      ],
      "metadata": {
        "id": "H_agwGnXlmSW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net1 = Net1()\n",
        "\n",
        "net.modules, net1.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44lKDWpTmqnJ",
        "outputId": "8f133889-0a50-4a79-d427-07de2a29644c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method Module.modules of Net(\n",
              "   (net): Sequential(\n",
              "     (0): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "     (1): ReLU()\n",
              "     (2): LazyLinear(in_features=0, out_features=1, bias=True)\n",
              "   )\n",
              " )>, <bound method Module.modules of Net1(\n",
              "   (linear1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "   (relu1): ReLU()\n",
              "   (linear2): LazyLinear(in_features=0, out_features=1, bias=True)\n",
              " )>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `groups` argument in `torch.nn.Conv2d()` and `torch.lazyConv2d()`:\n",
        "\n",
        "`groups` controls the connections between inputs and outputs. `in_channels` and `out_channels` must both be divisibe by `groups`.\n",
        "\n",
        "* At groups=1, all inputs are convolved to outputs.\n",
        "* At groups=2, the operation becomes equivalent to having two convolution layers side by side. Each seeing half the input channels and producing half the output channels, and both subsequently concatenated.\n",
        "\n"
      ],
      "metadata": {
        "id": "hee2m4vBoGIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Notes"
      ],
      "metadata": {
        "id": "RjS3Z1ls9T97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python `super()`\n",
        "\n",
        "Returns objects represented in the parent's class."
      ],
      "metadata": {
        "id": "xEgyiINR98Us"
      }
    }
  ]
}