{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSkekaWf23cgD7zxEhVC32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive-into-Deep-Learning-Notes-/blob/main/10_7_Encoder_Decoder_Machine_Translation_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGly9mBzOLvA",
        "outputId": "9283aa02-d65e-4082-faec-c1d9a8b33270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.7 Encoder-Decoder Seq2Seq for Machine Translation"
      ],
      "metadata": {
        "id": "ELgg6IAMOSJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.7.2 Encoder"
      ],
      "metadata": {
        "id": "q2PE_PYhVnZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "input_size, hidden_size, num_layers = 10, 20, 2\n",
        "rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
        "\n",
        "rnn._flat_weights_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb4UJzfAVsqm",
        "outputId": "6e97b43f-b5f6-47f8-8fae-b7a4f830e5fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['weight_ih_l0',\n",
              " 'weight_hh_l0',\n",
              " 'bias_ih_l0',\n",
              " 'bias_hh_l0',\n",
              " 'weight_ih_l1',\n",
              " 'weight_hh_l1',\n",
              " 'bias_ih_l1',\n",
              " 'bias_hh_l1']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn._parameters"
      ],
      "metadata": {
        "id": "aOOq8k38WtQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding\n",
        "* Embedding layer is equivalent to a linear layer without the bias term. However, embedding does a lookup instead of a matrix-vector multiplication.\n",
        "\n",
        "* An embedding is an efficient alternative way to a single linear layer when one has a large number of input features. This may happen in natural language processing (NLP) when one is working with text data.\n",
        "\n",
        "* Class `torch.nn.Embedding(num_embeddings, embedding_dim)`: A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "\n",
        "* This module is often used to score word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "* *num_embeddings(int)*: Size of the dictionary of embeddings.\n",
        "* *embedding_dim(int)*: The size of each embedding vector.\n",
        "\n",
        "**Shape:**\n",
        "\n",
        "* `input: (*)`: IntTensor or LongTensor of arbitrary shape containing the indices to extract.\n",
        "* `output(*, H)`: Where * is the input shape and H is `embedding_dim`. "
      ],
      "metadata": {
        "id": "8xyNSVT0XxIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, embed_size = 10, 8\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, embed_size)"
      ],
      "metadata": {
        "id": "G6gKHt74e3kC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, num_steps = 4, 9\n",
        "X = torch.zeros((batch_size, num_steps))\n",
        "\n",
        "embs = embedding(X.t().type(torch.int32))\n",
        "embs[0,:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOZGrMaMfrrE",
        "outputId": "bc350789-bdd8-4118-9ddd-ae1c052a28e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1544,  0.7103,  0.2287,  1.2542,  0.0098,  0.2911, -0.1725, -1.0152],\n",
              "        [-0.1544,  0.7103,  0.2287,  1.2542,  0.0098,  0.2911, -0.1725, -1.0152],\n",
              "        [-0.1544,  0.7103,  0.2287,  1.2542,  0.0098,  0.2911, -0.1725, -1.0152],\n",
              "        [-0.1544,  0.7103,  0.2287,  1.2542,  0.0098,  0.2911, -0.1725, -1.0152]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}