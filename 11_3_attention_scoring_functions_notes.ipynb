{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPaMJX2paf4Vg5xF5bmxuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive-into-Deep-Learning-Notes-/blob/main/11_3_attention_scoring_functions_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6OnYmhZA1vI",
        "outputId": "0147e6f4-7e17-476a-a95d-2e63ec640325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.3 Attention Scoring Functions"
      ],
      "metadata": {
        "id": "XRRWiy6vA_Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.2 Convenience Functions"
      ],
      "metadata": {
        "id": "Yfdxc4JkBH9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masked Softmax Operation"
      ],
      "metadata": {
        "id": "m31jhld_BI59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `tensor.size(dim=None)`: Returns the size of the given tensor."
      ],
      "metadata": {
        "id": "3Zj38nIRB0WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "X.size(), X.size(dim=0), X.size(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys_RH3adB9Sb",
        "outputId": "d9c9ca55-d24b-4b39-eded-42f565840a2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2]), 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch.nn.functional.softmax(input, dim=None)`: Applies a softmax function."
      ],
      "metadata": {
        "id": "vuBLR8TdDenf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 2)\n",
        "Y = torch.nn.functional.softmax(X)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM53W1coDomj",
        "outputId": "f61be286-01bd-4688-9fed-a6a3d38ebaa8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-829a4aae16de>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  Y = torch.nn.functional.softmax(X)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3722, 0.6278],\n",
              "        [0.5094, 0.4906]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.nn.functional.softmax(X, dim=0)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PJw8CVaEOAV",
        "outputId": "77f8eb8f-da69-4172-fb79-7a96b9d42fba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3963, 0.5347],\n",
              "        [0.6037, 0.4653]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch.repeat_interleave(input, repeats)`: Repeat elements of a tensor."
      ],
      "metadata": {
        "id": "RyjU-5LMFCgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 2], \n",
        "                  [3, 4]])\n",
        "Y = X.repeat_interleave(2)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLkWqvewFLmz",
        "outputId": "f57772c4-81bd-4989-bb97-9ba74378f410"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 2, 2, 3, 3, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = X.repeat_interleave(2, dim=1)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niH-t43vFaD1",
        "outputId": "6a00c420-953a-457e-b238-f458b2afa2c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 2, 2],\n",
              "        [3, 3, 4, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Slicing with `None` will add an axis to your array."
      ],
      "metadata": {
        "id": "AimuLcRXJVSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 2, 4)\n",
        "valid_lens = torch.tensor([2, 3])\n",
        "\n",
        "maxlen = X.size(1)\n",
        "print('Maximum length is: ', maxlen)\n",
        "\n",
        "mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                    device=X.device)\n",
        "print('Mask:', mask)\n",
        "print('Slicing with None on valid_len: ', valid_lens[:, None])\n",
        "print('Slicing with None on mask: ', mask[None, :])\n",
        "\n",
        "mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                    device=X.device)[None, :] < valid_lens[:, None]\n",
        "print('Mask: ', mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AeKDYYVGCGs",
        "outputId": "c74b5bc6-261d-41c4-bc8f-ca4b72b38357"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length is:  2\n",
            "Mask: tensor([0., 1.])\n",
            "Slicing with None on valid_len:  tensor([[2],\n",
            "        [3]])\n",
            "Slicing with None on mask:  tensor([[0., 1.]])\n",
            "Mask:  tensor([[True, True],\n",
            "        [True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[mask]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO5VRURGJ_Lf",
        "outputId": "6ae811c4-f03f-4117-b4d9-58ed74f11235"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0228, 0.7358, 0.2096, 0.5776],\n",
              "        [0.5998, 0.6103, 0.8716, 0.6612],\n",
              "        [0.1979, 0.1133, 0.1938, 0.1814],\n",
              "        [0.7725, 0.3279, 0.0037, 0.9926]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}