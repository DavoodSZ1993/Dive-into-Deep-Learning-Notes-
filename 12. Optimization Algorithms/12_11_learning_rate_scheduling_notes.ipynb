{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG2PLW41Wa7rWljcmFsu++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive-into-Deep-Learning-Notes-/blob/main/12_11_learning_rate_scheduling_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lvVpQ1iMtkt",
        "outputId": "3420b5e3-a495-4af7-9638-fe382d5f5033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.11 Learning Rate Scheduling"
      ],
      "metadata": {
        "id": "csH8XE9dM8cw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.11.1 Toy Problem"
      ],
      "metadata": {
        "id": "7BHQJd1NOYT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch.optim.lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "* Learning rate scheduling should be applied after optimizer's update."
      ],
      "metadata": {
        "id": "ESUOa2_HOcQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `torch.nn.CrossEntropyLoss()`: This criterion computes the cross-entropy between input logits and target.\n",
        "* It is useful when training a classification problem with C classes."
      ],
      "metadata": {
        "id": "L2aCq6a8Pr4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Updates to model parameters are handled by an *optimizer* in PyTorch. When we define the optimizer, you have the option of partitioning the model parameters into different groups, called `param_groups`. "
      ],
      "metadata": {
        "id": "ISEKP7U-U6ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "from torch.optim import lr_scheduler\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "RiUJSaEySDtM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(10, 20)\n",
        "    self.layer2 = nn.Linear(20, 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.layer2(self.layer1(X))"
      ],
      "metadata": {
        "id": "x0xojRj4S7BK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.3\n",
        "model = LinearModel()\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for param_group in trainer.param_groups:\n",
        "  print(param_group)\n"
      ],
      "metadata": {
        "id": "ZripI7rzTdtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.11.3 Policies"
      ],
      "metadata": {
        "id": "V3MVmtNyj8JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Factor Scheduler"
      ],
      "metadata": {
        "id": "3R-MZu2Yj_Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class `torch.optim.lr_scheduler.MultiStepRL(optimizer, milestones, gamma=0.1)`: Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones.\n",
        "* **optimizer**: wrapped optimzer\n",
        "* **milestones(list)**: List of epoch indices, must be increasing.\n",
        "* **gamma(float)**: Multiplicative factor of learning rate decay."
      ],
      "metadata": {
        "id": "F6MQiAMZkuw3"
      }
    }
  ]
}
